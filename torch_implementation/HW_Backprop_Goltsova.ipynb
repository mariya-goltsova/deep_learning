{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "lonely-delta",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lonely-delta"
      },
      "source": [
        "# Глубинное обучение, ИИ/МОЦП ВШЭ\n",
        "\n",
        "## Домашнее задание 1. Полносвязные нейронные сети. Бэкпроп.\n",
        "\n",
        "Максимально допустимая оценка за бонус — 10 баллов. Сдавать задание после указанного срока жесткого дедлайна нельзя.\n",
        "\n",
        "Сдача работы после мягкого дедлайна штрафуется ступенчато, -1 балл в сутки. Один раз за модуль студентам предоставляется возможность использовать отсрочку и сдать в жесткий дедлайн без штрафа.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "Использование генеративных моделей допустимо на следующих условиях:\n",
        "- Количество кода, написанное генеративными моделями, не превышает 30%\n",
        "- Указана модель, использованная для генерации, а также промпт\n",
        "- В конце работы необходимо описать свой опыт использования генеративного ИИ для решения данного домашнего задания. Укажите как часто Вам приходилось исправлять код своими руками или просить модель что-то исправить. Было ли это быстрее, чем написать код самим?\n",
        "\n",
        "В случае невыполнения этих требований работа не оценивается и оценка за неё не превышает 0 баллов.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит реализовать свой фреймворк для обучения нейронных сетей на основе `numpy`. Интерфейс фреймворка будет максимально копировать PyTorch, так что вы немного познакомитесь с тем, как все устроено изнутри. Директория `modules` содержит файлы с шаблонами фреймровка, а `tests` &mdash; тесты для проверки корректности ваших реализаций.\n",
        "\n",
        "Ячейка ниже повзоляет переподгружать питоновские модули, которые вы изменили после импорта, без необходимости перезапускать ноубук."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSKXty8v8DBy",
        "outputId": "34e92530-bed0-42c6-bd64-52d268b6f3fb"
      },
      "id": "NSKXty8v8DBy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/магистратура"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dtiswkQ8Tfk",
        "outputId": "6ddc0f93-c45a-47b0-c99e-c4d5b0caf7ce"
      },
      "id": "0dtiswkQ8Tfk",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/магистратура\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrVX_0h98VQR",
        "outputId": "25ab250f-19e6-4aa5-e5ba-fffe60eb8d43"
      },
      "id": "OrVX_0h98VQR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'cv_project_2025 [WSL_ Ubuntu] - Visual Studio Code 2026-01-14 10-16-46.mp4'\n",
            " HW_Backprop.ipynb\n",
            " \u001b[0m\u001b[01;34mmodules\u001b[0m/\n",
            " \u001b[01;34mtests\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "suspended-death",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "suspended-death"
      },
      "outputs": [],
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "lonely-component",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lonely-component"
      },
      "outputs": [],
      "source": [
        "import modules as mm\n",
        "import numpy as np\n",
        "import tests\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "optimum-mechanics",
      "metadata": {
        "id": "optimum-mechanics"
      },
      "source": [
        "## 0. Автоматическое дифференцирование\n",
        "\n",
        "Самый главным объектом в нашем фреймворке будет абстракция слоя (класс `Module`), которая реализована в файле `modules/base.py`. Перед тем как писать свой код, ознакомьтесь с реализацией класса `Module`. Каждый слой должен поддерживать две операции: проход вперед, который принимает выход предыдущего слоя и вычисляет функцию слоя, и проход назад, который принимает выход предыдущего слоя и производную по своему выходу, а возвращает производную по входу, попутно обновляя градиент по своим параметрам. Вспомним общую схему еще раз. Пусть $f(x, w)$ &mdash; это наша функция слоя, которая зависит от входа $x$ и параметров в $w$, $\\ell$ - функция потерь, градиент по параметрам которой нас интересует. Тогда:\n",
        "\n",
        "- Проход вперед:\n",
        "\n",
        "$$y = f(x, w)$$\n",
        "\n",
        "- Проход назад:\n",
        "\n",
        "$$\\frac{d\\ell}{dx} = \\frac{d\\ell}{dy} \\cdot \\frac{df(x, w)}{dx}$$\n",
        "\n",
        "$$\\frac{d\\ell}{dw} = \\frac{d\\ell}{dy} \\cdot \\frac{df(x, w)}{dw}$$\n",
        "\n",
        "Таким образом, при проходе вперед в слой передается $x$, при проходе назад $x$ и $\\frac{d\\ell}{dy}$. Кроме того, каждый слой сохраняет свой выход при проходе вперед, чтобы затем передать его в следующий слой при проходе назад. Сответственно, базовый класс `Module` реализует функции `forward` (или его alias, метод `__call__`, аналогично тому, как это сделано в PyTorch) и `backward`. Кроме того, шаблоны содержат некоторые служебные функции, в том числе `train` и `eval`, которые меняют режим слоя. Все слои, которые вам нужно реализовать, будут наследоваться от класса `Module`. В них потребуется реализовать методы `compute_output`, `compute_grad_input` и `update_grad_parameters` (если у слоя есть обучаемые параметры). За подробностями обращайтесь к док-строкам в шаблонах. Мы будем реализовывать слои аналогично соответствующим слоям из PyTorch, поэтому можете сверяться с документацией для уточнения значений параметров слоев. Для вашего удобства мы приводим тесты для отладки реализаций, ваше решение должно их проходить (баллы начисляются за пройденные тесты). В случае возникновения затруднений советуем дебажить код, сравнивая вашу реализацию с модулями из PyTorch.\n",
        "\n",
        "**Важно:** мы хотим получить такое же поведение, как у PyTorch, поэтому если сделать несколько проходов назад без вызова функции `zero_grad`, то градиенты со всех проходов назад должны суммироваться. Это значит, что в функции `update_grad_parameters` нужно прибавить новый градиент к уже имеющемуся, а не перезаписать его.\n",
        "\n",
        "Обратите внимание, что все ваши подсчеты функций и градиентов должны быть **векторизованными**, то есть включать только операции на `numpy`/`scipy` и **никаких питоновских циклов** (или оберток над ними из указанных библиотек). Специальные места, в которых циклы разрешены, будут указаны отдельно."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "traditional-vietnam",
      "metadata": {
        "id": "traditional-vietnam"
      },
      "source": [
        "## 1. Линейный слой (1 балл)\n",
        "\n",
        "- Прототип: [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "- Расположение: `modules.layers.Linear`\n",
        "\n",
        "Отныне мы будем иметь в виду, что вход нейросети $x$ имеет размер $B \\times N$, где $B$ &mdash; размер мини-батча, а $N$ &mdash; размерность. Функция слоя выглядит как:\n",
        "\n",
        "$$\n",
        "y = x \\, W^T + b,\n",
        "$$\n",
        "\n",
        "где $W \\in \\mathbb{R}^{M \\times N}, b \\in \\mathbb{R}^M$. Таким образом, выход слоя имеет размер $B \\times M$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "hired-modem",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hired-modem",
        "outputId": "23cc1b9e-c891-4529-cf32-f0274eb4b1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_linear ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_linear()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "improving-satellite",
      "metadata": {
        "id": "improving-satellite"
      },
      "source": [
        "## 2. Batch-нормализация (2.5 балла)\n",
        "\n",
        "- Прототип: [nn.BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d)\n",
        "- Расположение: `modules.layers.BatchNormalization`\n",
        "\n",
        "Batch-нормализация &mdash; первый слой, который работает по-разному в train и eval режимах.\n",
        "\n",
        "**Режим train:**\n",
        "\n",
        "1. Для каждой координаты входа считаем статистики по мини-батчу ($x_i \\in \\mathbb{R}^N$ &mdash; один объект в мини-батче):\n",
        "\n",
        "$$\n",
        "\\mu = \\frac{1}{B} \\sum_{i=1}^B x_i, \\quad\\quad \\mu \\in \\mathbb{R}^N \\\\\n",
        "\\sigma^2 = \\frac{1}{B} \\sum_{i=1}^B (x_i - \\mu)^2, \\quad\\quad \\sigma^2 \\in \\mathbb{R}^N\n",
        "$$\n",
        "\n",
        "Обратите внимание, что здесь используется **смещенная** оценка дисперсии (то есть мы делим сумму квадратов отклонений на $B$, а не на $B-1$).\n",
        "\n",
        "2. Нормируем вход с учетом статистик:\n",
        "\n",
        "$$\n",
        "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\varepsilon}}\n",
        "$$\n",
        "\n",
        "3. Применяем афинное преобразование к нормированному входу (если `affine = True`), умножение поэлементное. Это и будет выход слоя.\n",
        "\n",
        "$$\n",
        "y_i = \\hat{x}_i * w + b, \\quad\\quad w, b \\in \\mathbb{R}^N\n",
        "$$\n",
        "\n",
        "4. Обновляем бегущие статистики слоя:\n",
        "\n",
        "$$\n",
        "\\text{running mean} = (1 - \\text{momentum}) \\cdot \\text{running mean} + \\text{momentum} \\cdot \\mu \\\\\n",
        "\\text{running var} = (1 - \\text{momentum}) \\cdot \\text{running var} + \\text{momentum} \\cdot \\frac{B}{B - 1}\n",
        "\\cdot \\sigma^2\n",
        "$$\n",
        "\n",
        "Здесь перенормировка $\\sigma^2$ необходима, чтобы обновлять бегущую дисперсию **несмещенной** оценкой (точно так же это реализовано в PyTorch).\n",
        "\n",
        "К параметрам слоя, которые обновляются градиентом, относятся только $w$ (`weight`) и $b$ (`bias`), но не `running mean` и `running var`.\n",
        "\n",
        "**Режим eval:**\n",
        "\n",
        "1. Нормируем вход, используя бегущие статистики:\n",
        "\n",
        "$$\n",
        "\\hat{x}_i = \\frac{x_i - \\text{running mean}}{\\sqrt{\\text{running var} + \\varepsilon}}\n",
        "$$\n",
        "\n",
        "2. Применяем афинное преобразование к нормированному входу:\n",
        "\n",
        "$$\n",
        "y_i = \\hat{x}_i * w + b\n",
        "$$\n",
        "\n",
        "**Хозяйке на заметку**\n",
        "\n",
        "- Убедитесь, что проход назад корректно работает и для train, и для eval режимов\n",
        "- Сохраняйте промежуточные вычисления при проходе вперед, чтобы переиспользовать их при проходе назад\n",
        "- Весьма вероятно, что у вас не получится правильная реализация с первого раза. Не отчаивайтесь, автор задания тоже потратил не один час, пока этот модуль не заработал. Если чувствуете, что зашли в тупик, то пользоваться гуглом никто не запрещал, но не забудьте указать источники, которыми пользуетесь."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "every-prison",
      "metadata": {
        "id": "every-prison",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9226eb9b-9b5c-49ac-d19a-2306fc7ec59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bn ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_bn()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "successful-dover",
      "metadata": {
        "id": "successful-dover"
      },
      "source": [
        "## 3. Dropout (1 балл)\n",
        "\n",
        "- Прототип: [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)\n",
        "- Расположение: `modules.layers.Dropout`\n",
        "\n",
        "Dropout &mdash; еще один слой, чье поведение различно в train и eval режимах. Поведения слоя регулируется параметром $p$ &mdash; вероятностью занулить координату входа.\n",
        "\n",
        "**Режим train:**\n",
        "\n",
        "Обозначим за $m$ бинарную маску, имеющую такой же размер, как вход $x$. Маска генерируется по правилу $m_{ij} \\sim \\text{Bernoulli}(1-p)$. При этом при каждом новом проходе вперед генерируется новая маска (то есть она не фиксирована). Функция слоя (умножение поэлементное):\n",
        "\n",
        "$$\n",
        "y = \\frac{1}{1-p} m * x\n",
        "$$\n",
        "\n",
        "Нормализация на $1-p$ необходима, чтобы среднее значение нейронов входа не изменилось.\n",
        "\n",
        "**Режим eval:**\n",
        "\n",
        "Здесь все предельно просто: вход слоя никаких не изменяется $y=x$.\n",
        "\n",
        "**Хозяйке на заметку**\n",
        "\n",
        "- Убедитесь, что проход назад корректно работает и для train, и для eval режимов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "collective-western",
      "metadata": {
        "id": "collective-western",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d541dd8a-cb66-4f01-8da2-f3a4d8198c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_dropout ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_dropout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "appointed-metropolitan",
      "metadata": {
        "id": "appointed-metropolitan"
      },
      "source": [
        "## 4. Функции активации (1.5 балла)\n",
        "\n",
        "### ReLU\n",
        "\n",
        "- Прототип: [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "- Расположение: `modules.activations.ReLU`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y = \\max(x, 0)\n",
        "$$\n",
        "\n",
        "### Sigmoid\n",
        "\n",
        "- Прототип: [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html?highlight=nn%20sigmoid#torch.nn.Sigmoid)\n",
        "- Расположение: `modules.activations.Sigmoid`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y = \\frac{1}{1 + e^{-x}}\n",
        "$$\n",
        "\n",
        "### Softmax\n",
        "\n",
        "- Прототип: [nn.Softmax](http://bit.ly/get3a)\n",
        "- Расположение: `modules.activations.Softmax`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y_{ij} = \\frac{\\exp(x_{ij})}{\\sum_{k=1}^{N} \\exp(x_{ik})}\n",
        "$$\n",
        "\n",
        "### LogSoftmax\n",
        "\n",
        "- Прототип: [nn.LogSoftmax](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html?highlight=log%20softmax#torch.nn.LogSoftmax)\n",
        "- Расположение: `modules.activations.LogSoftmax`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y_{ij} = \\log \\left(\\frac{\\exp(x_{ij})}{\\sum_{k=1}^{N} \\exp(x_{ik})}\\right)\n",
        "$$\n",
        "\n",
        "**Хозяйке на заметку**\n",
        "\n",
        "- Пользуйтесь функциями из `scipy.special`\n",
        "- Реализовывать `LogSoftmax` как логарифм от модуля `Softmax` &mdash; плохая идея"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "great-sector",
      "metadata": {
        "id": "great-sector",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15c2d98-5bb5-42e0-80b6-4458dae64ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_activations ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_activations()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "disabled-proof",
      "metadata": {
        "id": "disabled-proof"
      },
      "source": [
        "## 5. Контейнер Sequential (1 балл)\n",
        "\n",
        "- Прототип: [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "- Расположение: `modules.layers.Sequential`\n",
        "\n",
        "Контейнер-обертка, который применяет слои последовательно.\n",
        "\n",
        "**Важно:** здесь разрешен цикл по модулям при проходах вперед и назад."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "standard-electron",
      "metadata": {
        "id": "standard-electron",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a82cbb-0849-4056-9e6f-0457163d5e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_sequential ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extensive-mirror",
      "metadata": {
        "id": "extensive-mirror"
      },
      "source": [
        "## 6. Функции потерь (1 балл)\n",
        "\n",
        "Функции потерь отличаются от всех остальных модулей тем, что являются стоком вычислительного графа (то есть из них нет исходящих операций). Это означает, что с них начинается проход назад, поэтому интерфейс функции `compute_grad_input` выглядит иначе: вместо входа модуля и производной по выходу в функцию приходит предсказание нейронной сети (производная по которому нас и интересует, чтобы запустить проход назад) и целевая переменная. Базовый класс для всех функций потерь &mdash; `modules.base.Criterion`.\n",
        "\n",
        "### MSE\n",
        "\n",
        "- Прототип: [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)\n",
        "- Расположение: `modules.criterions.MSELoss`\n",
        "\n",
        "Пусть $f \\in \\mathbb{R}^{B\\times N}$ &mdash; предсказание нейронной сети, а $y \\in \\mathbb{R}^{B\\times N}$ &mdash; целевая переменная. Функция потерь выглядит как:\n",
        "\n",
        "$$\n",
        "\\ell(f, y) = \\frac{1}{BN} \\sum_{i=1}^B \\sum_{j=1}^N (f_{ij} - y_{ij})^2\n",
        "$$\n",
        "\n",
        "### Cross Entropy\n",
        "\n",
        "- Прототип: [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "- Расположение: `modules.criterions.CrossEntropyLoss`\n",
        "\n",
        "Кросс-энтропия &mdash; это функция потерь для обучения классификаторов. Пусть $f \\in \\mathbb{R}^{B\\times C}$ (где $C$ &mdash; число классов) &mdash; предсказание нейронной сети (это так называемые *логиты*, обычно выходы линейного слоя без активации, потому могут быть любыми вещественными числами), а $y \\in \\{1, \\dots, C\\}^B$ &mdash; целевая переменная (номер класса соответствующего объекта). Функция потерь вычисляется как:\n",
        "\n",
        "$$\n",
        "p_{ic} = \\frac{\\exp(f_{ic})}{\\sum_{k=1}^C \\exp(f_{ik})}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\ell(f, y) = -\\frac{1}{B} \\sum_{i=1}^B \\sum_{c=1}^C [c = y_i] \\log p_{ic}\n",
        "$$\n",
        "\n",
        "При этом, $p_{ic}$ &mdash; это вероятность класса $с$ для объекта $i$, которую предсказывает нейронная сеть.\n",
        "\n",
        "**Важно:** вычисление Softmax, а затем логарифма от него &mdash; численно нестабильная операция. Воспользуйтесь слоем LogSoftmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "early-hampshire",
      "metadata": {
        "id": "early-hampshire",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598d6819-f99f-4ba9-f74f-8eaefe4fd374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_criterions ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_criterions()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "steady-edition",
      "metadata": {
        "id": "steady-edition"
      },
      "source": [
        "## 7. Оптимизаторы (1.5 балла)\n",
        "\n",
        "Оптимизатор &mdash; вспомогательный класс, который обновляет веса нейронной сети при градиентном спуске, используя сохраненные градиенты параметров. Базовый класс &mdash; `modules.base.Optimizer`. В документации PyTorch приведен псевдокод с описанием алгоритмов, советуем обратиться туда.\n",
        "\n",
        "**Важно:** здесь разрешен цикл по параметрам и градиентам (см. шаблоны)\n",
        "\n",
        "### SGD\n",
        "\n",
        "- Прототип: [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n",
        "- Расположение: `modules.optimizers.SGD`\n",
        "\n",
        "### Adam\n",
        "\n",
        "- Прототип: [torch.optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- Расположение: `modules.criterions.CrossEntropyLoss`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "selected-cuisine",
      "metadata": {
        "id": "selected-cuisine",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1dbeb4b-8775-4afa-d494-718f150dd826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_optimizers ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_optimizers()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "centered-therapist",
      "metadata": {
        "id": "centered-therapist"
      },
      "source": [
        "## 8. DataLoader (0.5 балла)\n",
        "\n",
        "- Прототип: [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "- Расположение: `modules.dataloader.DataLoader`\n",
        "\n",
        "И последнее, что нам осталось реализовать &mdash; это DataLoader, который перемешивает данные раз в эпоху (если это необходимо) и формирует из них мини-батчи. Технически, это будет питоновский итератор. Вот краткое [руководство](https://stackoverflow.com/questions/19151/how-to-build-a-basic-iterator), как написать итератор.\n",
        "\n",
        "Обратите внимание, что ваша реализация должна уметь работать как с одномерным массивом целевой переменной (с формой `(num_samples, )` &mdash; так будет удобнее учить нейронную сеть на кросс-энтропию), так и с двумерной версией (с формой`(num_samples, 1)` &mdash; сответственно, на MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ready-trance",
      "metadata": {
        "id": "ready-trance",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda0b4d3-fd45-4efe-9471-565f54a027b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_dataloader ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "active-algorithm",
      "metadata": {
        "id": "active-algorithm"
      },
      "source": [
        "## Собираем все вместе\n",
        "\n",
        "Если вы все сделали правильно, то следующий кусок кода с обучением нейронной сети должен заработать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "super-latest",
      "metadata": {
        "id": "super-latest"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X_train = np.random.randn(2048, 8)\n",
        "X_test = np.random.randn(512, 8)\n",
        "y_train = np.sin(X_train).sum(axis=1, keepdims=True)\n",
        "y_test = np.sin(X_test).sum(axis=1, keepdims=True)\n",
        "\n",
        "train_loader = mm.DataLoader(X_train, y_train, batch_size=64, shuffle=True)\n",
        "test_loader = mm.DataLoader(X_test, y_test, batch_size=64, shuffle=False)\n",
        "\n",
        "model = mm.Sequential(\n",
        "    mm.Linear(8, 32),\n",
        "    mm.BatchNormalization(32),\n",
        "    mm.ReLU(),\n",
        "    mm.Linear(32, 64),\n",
        "    mm.Dropout(0.25),\n",
        "    mm.Sigmoid(),\n",
        "    mm.Linear(64, 1),\n",
        ")\n",
        "optimizer = mm.Adam(model, lr=1e-2)\n",
        "criterion = mm.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "gothic-latin",
      "metadata": {
        "id": "gothic-latin",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "88734c04923e4192aff9b7e99d636142",
            "6fb041c4f98741bb96acd9dc8eeedbac",
            "6a55b25a157440a89966d72bd424fc37",
            "8db3b7d05941412b964dd381385f00d1",
            "fb951a27b7bb4a6a8c6ddb65b7c150cb",
            "3eccb2dec2494131864b64b2a9747a94",
            "8d6126f747204bbc9de9710ef88f9e9b",
            "7f722b416f4d4ca5a392e1aa7a5c0626",
            "b7201ebf56ef4fa9bbff77444cc5f075",
            "cc15933f567540dc8c2e5fd8275c0f94",
            "837d5fdb43124d73aeaf5da018a79efe"
          ]
        },
        "outputId": "9c298a6f-35a5-4e83-d383-a9523575c7a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88734c04923e4192aff9b7e99d636142"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "pbar = tqdm(range(1, num_epochs + 1))\n",
        "\n",
        "for epoch in pbar:\n",
        "    train_loss, test_loss = 0.0, 0.0\n",
        "\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        model.backward(X_batch, criterion.backward(predictions, y_batch))\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss * X_batch.shape[0]\n",
        "\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        test_loss += loss * X_batch.shape[0]\n",
        "\n",
        "    train_loss /= train_loader.num_samples()\n",
        "    test_loss /= test_loader.num_samples()\n",
        "    pbar.set_postfix({\"train loss\": train_loss, \"test loss\": test_loss})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aware-district",
      "metadata": {
        "id": "aware-district"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88734c04923e4192aff9b7e99d636142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fb041c4f98741bb96acd9dc8eeedbac",
              "IPY_MODEL_6a55b25a157440a89966d72bd424fc37",
              "IPY_MODEL_8db3b7d05941412b964dd381385f00d1"
            ],
            "layout": "IPY_MODEL_fb951a27b7bb4a6a8c6ddb65b7c150cb"
          }
        },
        "6fb041c4f98741bb96acd9dc8eeedbac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eccb2dec2494131864b64b2a9747a94",
            "placeholder": "​",
            "style": "IPY_MODEL_8d6126f747204bbc9de9710ef88f9e9b",
            "value": "100%"
          }
        },
        "6a55b25a157440a89966d72bd424fc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f722b416f4d4ca5a392e1aa7a5c0626",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7201ebf56ef4fa9bbff77444cc5f075",
            "value": 100
          }
        },
        "8db3b7d05941412b964dd381385f00d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc15933f567540dc8c2e5fd8275c0f94",
            "placeholder": "​",
            "style": "IPY_MODEL_837d5fdb43124d73aeaf5da018a79efe",
            "value": " 100/100 [00:05&lt;00:00, 20.44it/s, train loss=0.245, test loss=0.26]"
          }
        },
        "fb951a27b7bb4a6a8c6ddb65b7c150cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eccb2dec2494131864b64b2a9747a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d6126f747204bbc9de9710ef88f9e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f722b416f4d4ca5a392e1aa7a5c0626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7201ebf56ef4fa9bbff77444cc5f075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc15933f567540dc8c2e5fd8275c0f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "837d5fdb43124d73aeaf5da018a79efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}